# RAG Chatbot Application

## Overview
The RAG (Retrieval-Augmented Generation) Chatbot Application leverages the capabilities of the LlamaIndex, Qdrant, and Streamlit to create a powerful and interactive chatbot. This application is designed to process and answer queries based on an input pdf documents.

## Architecture
- **Streamlit**: Provides the frontend interface for user interactions, such as uploading documents and asking questions.
- **LlamaIndex**: Utilizes advanced NLP techniques to index the uploaded documents and prepare them for efficient retrieval.
- **Qdrant**: Serves as the vector database to store and manage the high-dimensional vectors representing the text data for quick similarity searches.
- **RAG Pipeline**: Combines retrieval and language generation capabilities to fetch the most relevant information from the corpus and generate coherent, context-aware responses.

## How It Works
1. **Data Ingestion**: Users upload documents, which are then read and indexed by LlamaIndex. The text data is converted into high-dimensional vectors and stored in Qdrant.
2. **Query Processing**: When a user inputs a query, the system retrieves the most relevant vectors from Qdrant.
3. **Response Generation**: Using the retrieved vectors as context, LlamaIndex synthesizes a response that is both relevant and informative, leveraging the underlying language model.

## Setup and Installation
1. Install the required dependencies:

`pip install -r requirements.txt`

2. Run the application:

`streamlit run app.py`


## Usage
- **Uploading Data**: Use the file uploader in the Streamlit interface to upload your text documents.
- **Asking Questions**: Type your questions into the chat interface and receive responses generated by the RAG pipeline.

## Customization
The application can be customized to suit various needs, including adjusting the language model, tuning the retrieval mechanism as well as the RAG pipeline, and modifying the user interface.